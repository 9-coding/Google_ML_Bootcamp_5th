{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "sourceId": 63056,
          "databundleVersionId": 9094797,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30747,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/9-coding/Kaggle/blob/main/ISIC_2024/image_classification_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Requirements"
      ],
      "metadata": {
        "id": "SD47vQTMRmj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import h5py\n",
        "from PIL import Image\n",
        "from io import BytesIO\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torch.cuda import amp\n",
        "\n",
        "import torchvision\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms"
      ],
      "metadata": {
        "id": "NDMFwD55Rmj5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Configuration and Set Seed"
      ],
      "metadata": {
        "id": "p2bPBQ57Rmj6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "CONFIG = {\n",
        "    \"seed\": 42,\n",
        "    \"img_size\": 256,\n",
        "    \"batch_size\": 1024,\n",
        "    \"device\": torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\"),\n",
        "}"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-04T07:23:50.293626Z",
          "iopub.status.idle": "2024-08-04T07:23:50.293965Z",
          "shell.execute_reply.started": "2024-08-04T07:23:50.293803Z",
          "shell.execute_reply": "2024-08-04T07:23:50.293817Z"
        },
        "trusted": true,
        "id": "3Dm3Yhu-Rmj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def set_seed(seed=42):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    # When running on the CuDNN backend, two further options must be set\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    # Set a fixed value for the hash seed\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "\n",
        "set_seed(CONFIG['seed'])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-04T07:23:50.294920Z",
          "iopub.status.idle": "2024-08-04T07:23:50.295247Z",
          "shell.execute_reply.started": "2024-08-04T07:23:50.295089Z",
          "shell.execute_reply": "2024-08-04T07:23:50.295103Z"
        },
        "trusted": true,
        "id": "xO_GP4RYRmj6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ROOT_DIR = \"/kaggle/input/isic-2024-challenge\"\n",
        "\n",
        "TEST_HDF  = f'{ROOT_DIR}/test-image.hdf5'\n",
        "TEST_CSV  = f'{ROOT_DIR}/test-metadata.csv'\n",
        "IMAGE_HDF = f'{ROOT_DIR}/train-image.hdf5'\n",
        "TARGET_CSV = f'{ROOT_DIR}/train-metadata.csv'\n",
        "SAMPLE    = f'{ROOT_DIR}/sample_submission.csv'"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "execution": {
          "iopub.status.busy": "2024-08-04T07:23:50.296300Z",
          "iopub.status.idle": "2024-08-04T07:23:50.296647Z",
          "shell.execute_reply.started": "2024-08-04T07:23:50.296460Z",
          "shell.execute_reply": "2024-08-04T07:23:50.296494Z"
        },
        "trusted": true,
        "id": "VtINicKtRmj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data Configuration"
      ],
      "metadata": {
        "id": "i3_AvcJYRmj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(TARGET_CSV)\n",
        "print(len(df))\n",
        "df.head()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-04T07:23:50.298032Z",
          "iopub.status.idle": "2024-08-04T07:23:50.298353Z",
          "shell.execute_reply.started": "2024-08-04T07:23:50.298195Z",
          "shell.execute_reply": "2024-08-04T07:23:50.298209Z"
        },
        "trusted": true,
        "id": "iTDmk-0qRmj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset and DataLoader"
      ],
      "metadata": {
        "id": "OlIiBQ4KRmj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ISIC(Dataset):\n",
        "    def __init__(self, file_hdf, df, transforms):\n",
        "        self.fp_hdf = h5py.File(file_hdf, mode=\"r\")\n",
        "        self.df = df\n",
        "        self.isic_ids = df['isic_id'].values\n",
        "        self.targets = df['target'].values\n",
        "        self.transforms = transforms\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.isic_ids)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        isic_id = self.isic_ids[index]\n",
        "        img = Image.open(BytesIO(self.fp_hdf[isic_id][()]))\n",
        "        target = self.targets[index]\n",
        "\n",
        "        if self.transforms:\n",
        "            img = self.transforms(img)\n",
        "\n",
        "        return {\n",
        "            'image': img,\n",
        "            'target': target,\n",
        "        }"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-04T07:23:50.299943Z",
          "iopub.status.idle": "2024-08-04T07:23:50.300267Z",
          "shell.execute_reply.started": "2024-08-04T07:23:50.300109Z",
          "shell.execute_reply": "2024-08-04T07:23:50.300123Z"
        },
        "trusted": true,
        "id": "uiFZgzxkRmj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transforms_data = transforms.Compose([transforms.Resize((128,128)), transforms.ToTensor()])\n",
        "dataset = ISIC(IMAGE_HDF, df, transforms=transforms_data)\n",
        "dataset_size = len(dataset)\n",
        "\n",
        "train_size = int(dataset_size * 0.8)                     # 80%\n",
        "validation_size = int(dataset_size * 0.1)                # 10%\n",
        "test_size = dataset_size - train_size - validation_size  # 10%\n",
        "\n",
        "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, validation_size, test_size])\n",
        "\n",
        "print(f\"Training Data Size : {len(train_dataset)}\")\n",
        "print(f\"Validation Data Size : {len(val_dataset)}\")\n",
        "print(f\"Testing Data Size : {len(test_dataset)}\")\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=CONFIG['batch_size'], shuffle=True, pin_memory=True, drop_last=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=CONFIG['batch_size'], shuffle=False, pin_memory=True, drop_last=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=CONFIG['batch_size'], shuffle=False, pin_memory=True, drop_last=True)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-04T07:23:50.301253Z",
          "iopub.status.idle": "2024-08-04T07:23:50.301588Z",
          "shell.execute_reply.started": "2024-08-04T07:23:50.301400Z",
          "shell.execute_reply": "2024-08-04T07:23:50.301414Z"
        },
        "trusted": true,
        "id": "HMTcr6EiRmj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### GPU Setting ###\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "print(DEVICE)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-04T07:23:50.302847Z",
          "iopub.status.idle": "2024-08-04T07:23:50.303170Z",
          "shell.execute_reply.started": "2024-08-04T07:23:50.303010Z",
          "shell.execute_reply": "2024-08-04T07:23:50.303024Z"
        },
        "trusted": true,
        "id": "_2Cd7eUDRmj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCH = 30\n",
        "lr = 0.1\n",
        "model = models.resnet18(pretrained=True)\n",
        "\n",
        "### Transfer Learning ###\n",
        "num_features = model.fc.in_features\n",
        "model.fc = nn.Linear(num_features, 50)\n",
        "model.to(DEVICE)\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "print(\"Created a learning model and optimizer\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-04T07:23:50.304537Z",
          "iopub.status.idle": "2024-08-04T07:23:50.304863Z",
          "shell.execute_reply.started": "2024-08-04T07:23:50.304705Z",
          "shell.execute_reply": "2024-08-04T07:23:50.304719Z"
        },
        "trusted": true,
        "id": "mqbp2892Rmj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Train/Evaluation ###\n",
        "def train(model, train_loader, optimizer, epoch):\n",
        "  model.train()\n",
        "  train_loader_tqdm = tqdm(train_loader, desc=f\"Epoch {epoch}\", leave=False)\n",
        "  for i, batch in enumerate(train_loader_tqdm):\n",
        "    image, target = batch['image'].to(DEVICE), batch['target'].to(DEVICE)\n",
        "\n",
        "    output = model(image)\n",
        "    optimizer.zero_grad()\n",
        "    train_loss = F.cross_entropy(output, target).to(DEVICE)\n",
        "\n",
        "    train_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "  return train_loss"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-04T07:23:50.306557Z",
          "iopub.status.idle": "2024-08-04T07:23:50.307242Z",
          "shell.execute_reply.started": "2024-08-04T07:23:50.306990Z",
          "shell.execute_reply": "2024-08-04T07:23:50.307011Z"
        },
        "trusted": true,
        "id": "myWtu3XlRmj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, val_loader):\n",
        "  model.eval()\n",
        "  eval_loss = 0\n",
        "  correct = 0\n",
        "  with torch.no_grad():\n",
        "    for i, batch in tqdm(enumerate(val_loader)):\n",
        "      image, target = batch['image'].to(DEVICE), batch['target'].to(DEVICE)\n",
        "      output = model(image)\n",
        "      eval_loss += F.cross_entropy (output, target, reduction='sum').item()\n",
        "      pred = output.max(1, keepdim=True)[1]\n",
        "      correct += pred.eq(target.view_as (pred)).sum().item()\n",
        "    eval_loss /= len(val_loader.dataset)\n",
        "    eval_accuracy = 100 * correct / len(val_loader.dataset)\n",
        "    return eval_loss, eval_accuracy"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-04T07:23:50.308244Z",
          "iopub.status.idle": "2024-08-04T07:23:50.308686Z",
          "shell.execute_reply.started": "2024-08-04T07:23:50.308444Z",
          "shell.execute_reply": "2024-08-04T07:23:50.308462Z"
        },
        "trusted": true,
        "id": "XZ-vKaJFRmj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Main ###\n",
        "start = time.time()\n",
        "best = 0\n",
        "for epoch in range(EPOCH):\n",
        "  train_loss = train(model, train_loader, optimizer, epoch)\n",
        "  val_loss, val_accuracy = evaluate(model, val_loader)\n",
        "\n",
        "  # Save best model\n",
        "  if val_accuracy > best:\n",
        "    best = val_accuracy\n",
        "    torch.save(model.state_dict(), \"./best_model.pth\")\n",
        "  print(f'[{epoch}] Validation Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}%')\n",
        "\n",
        "# Test result\n",
        "test_loss, test_accuracy = evaluate(model, test_loader)\n",
        "wandb.log({'test_accuracy': test_accuracy})\n",
        "print(f'[FINAL] Test Loss {test_loss:.4f}, Accuracy: {test_accuracy:.4f}%')\n",
        "end = time.time()\n",
        "elasped_time = end - start\n",
        "\n",
        "print(\"Best Accuracy: \", best)\n",
        "print(f\"Elasped Time: {int(elasped_time/3600)}h, {int(elasped_time/60)}m, {int(elasped_time%60)}s\")\n",
        "print(f\"time: {int (elasped_time/3600)}h, {int(elasped_time/60)}m, {int(elasped_time%60)}s\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-08-04T07:23:50.310354Z",
          "iopub.status.idle": "2024-08-04T07:23:50.310706Z",
          "shell.execute_reply.started": "2024-08-04T07:23:50.310542Z",
          "shell.execute_reply": "2024-08-04T07:23:50.310557Z"
        },
        "trusted": true,
        "id": "Dd5Cc9_VRmj7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}